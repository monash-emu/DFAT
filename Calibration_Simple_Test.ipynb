{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival.priors import UniformPrior\n",
    "from estival.targets import NegativeBinomialTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summer2 import CompartmentalModel\n",
    "from summer2.parameters import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a simple SEIR model (based on https://www.frontiersin.org/articles/10.3389/fams.2023.1124897/full#T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    m = CompartmentalModel([0,100], [\"S\",\"E\",\"I\",\"R\"],\"I\",ref_date=datetime(2023,1,1))\n",
    "    m.set_initial_population({\"S\": 166198.0, \"E\": 16797.0, \"I\": 481.0, \"R\": 487.0})\n",
    "    m.add_importation_flow(\"recruitment\", num_imported=33595, dest=\"S\", split_imports=True) #A\n",
    "    m.add_universal_death_flows(\"universal_death\", death_rate=0.143) #mu\n",
    "    m.add_infection_density_flow(\"infection\", Parameter(\"contact_rate\"),\"S\",\"E\") #alpha I\n",
    "    m.add_transition_flow(\"partial_vax\", 0.2522,\"S\",\"E\") #V_p\n",
    "    m.add_transition_flow(\"full_vax\", 0.1517,\"S\",\"R\") #V_f\n",
    "    m.add_transition_flow(\"progression\", Parameter(\"progression\"),\"E\",\"I\") #delta\n",
    "    m.add_transition_flow(\"recovery\", 0.09,\"I\",\"R\") #gamma\n",
    "    m.add_death_flow(\"disease_death\", 0.1595,\"I\") #mu_1\n",
    "    m.request_output_for_flow(\"infection\", \"infection\")\n",
    "    m.request_output_for_flow(\"recovery\", \"recovery\")\n",
    "    m.request_output_for_flow(\n",
    "        \"progressions\",\n",
    "        \"progression\"\n",
    "    )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_input_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"contact_rate\": 0.00001, \"progression\": 1.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.run(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_outputs_df().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_derived_outputs_df().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = m.get_derived_outputs_df()[\"progressions\"]\n",
    "ndata = ndata[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets represent data we are trying to fit to\n",
    "from estival import targets as est\n",
    "\n",
    "# We specify parameters using (Bayesian) priors\n",
    "from estival import priors as esp\n",
    "\n",
    "# Finally we combine these with our summer2 model in a BayesianCompartmentalModel (BCM)\n",
    "from estival.model import BayesianCompartmentalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    est.NormalTarget(\"progressions\", ndata, np.std(ndata) * 0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = [\n",
    "    esp.UniformPrior(\"contact_rate\", (0.0,0.5)),\n",
    "    esp.UniformPrior(\"progression\", (0.5,1.5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defp = {\"contact_rate\": 0.00002, \"progression\": 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm = BayesianCompartmentalModel(m, defp, priors, targets)\n",
    "from estival.wrappers import pymc as epm\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "\n",
    "    # This is all you need - a single call to use_model\n",
    "    variables = epm.use_model(bcm)\n",
    "\n",
    "    # The log-posterior value can also be output, but may incur additional overhead\n",
    "    # Use jacobian=False to get the unwarped value (ie just the 'native' density of the priors\n",
    "    # without transformation correction factors)\n",
    "    # pm.Deterministic(\"logp\", model.logp(jacobian=False))\n",
    "\n",
    "    # Now call a sampler using the variables from use_model\n",
    "    # In this case we use the Differential Evolution Metropolis sampler\n",
    "    # See the PyMC docs for more details\n",
    "    idata = pm.sample(step=[pm.DEMetropolis(variables)], draws=4000, tune=0,cores=4,chains=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, figsize=(16,3.2*len(idata.posterior)),compact=False);#, lines=[(\"m\", {}, mtrue), (\"c\", {}, ctrue)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(idata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Obtaining Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival.sampling.tools import likelihood_extras_for_idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_df = likelihood_extras_for_idata(idata, bcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf_pivot = likelihood_df.reset_index(level=\"chain\").pivot(columns=[\"chain\"])\n",
    "\n",
    "ldf_pivot[\"logposterior\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort this DataFrame by logposterior to obtain the MAP index\n",
    "ldf_sorted = likelihood_df.sort_values(by=\"logposterior\",ascending=False)\n",
    "\n",
    "# Extract the parameters from the calibration samples\n",
    "map_params = idata.posterior.to_dataframe().loc[ldf_sorted.index[0]].to_dict()\n",
    "\n",
    "map_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm.loglikelihood(**map_params), ldf_sorted.iloc[0][\"loglikelihood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res = bcm.run(map_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"progressions\"\n",
    "\n",
    "pd.Series(map_res.derived_outputs[variable]).plot(title = f\"{variable} (MLE)\")\n",
    "bcm.targets[variable].data.plot(style='.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idata = az.extract(idata, num_samples = 400)\n",
    "samples_df = sample_idata.to_dataframe().drop(columns=[\"chain\",\"draw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival.utils.parallel import map_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sample(idx_sample):\n",
    "    idx, params = idx_sample\n",
    "    return idx, bcm.run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_res = map_parallel(run_sample, samples_df.iterrows(), n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xres = xr.DataArray(np.stack([r.derived_outputs for idx, r in sample_res]),\n",
    "                    dims=[\"sample\",\"time\",\"variable\"])\n",
    "xres = xres.assign_coords(sample=sample_idata.coords[\"sample\"],\n",
    "                          time=map_res.derived_outputs.index, variable=map_res.derived_outputs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some quantiles to calculate\n",
    "quantiles = (0.01,0.05,0.25,0.5,0.75,0.95,0.99)\n",
    "\n",
    "# Generate a new DataArray containing the quantiles\n",
    "xquantiles = xres.quantile(quantiles,dim=[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract these values to a pandas DataFrame for ease of plotting\n",
    "\n",
    "uncertainty_df = xquantiles.to_dataframe(name=\"value\").reset_index().set_index(\"time\").pivot(columns=(\"variable\",\"quantile\"))[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"progressions\"\n",
    "\n",
    "fig = uncertainty_df[variable].plot(title=variable,alpha=0.7)\n",
    "pd.Series(map_res.derived_outputs[variable]).plot(style='--')\n",
    "bcm.targets[variable].data.plot(style='.',color=\"black\", ms=3, alpha=0.8);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
